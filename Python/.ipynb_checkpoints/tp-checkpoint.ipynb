{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> OPTIM - Projet sur les réseaux de distribution d’eau <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Clément Grisi & Mathieu Lerouge <center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Séance de travaux pratiques 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.a. Quelques éléments de calculs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le critère $F$ est donné par\n",
    "\n",
    "\\begin{align*}\n",
    "  F ~ \\colon \\quad \\mathbb{R}^{n-m_d} &\\to \\mathbb{R}\\\\\n",
    "  q_c &\\mapsto F(q_c) = \\frac{1}{3} \\langle q^{(0)} + B q_c, r ~\\bullet~ (q^{(0)} + B q_c) ~\\bullet~ \\vert q^{(0)} + B q_c \\vert \\rangle + \\langle p_r, A_r (q^{(0)} + Bq_c) \\rangle\n",
    "\\end{align*}\n",
    "\n",
    "où $a ~\\bullet~ b$ désigne le produit matriciel de Hadamard (produit composante par composante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posons les fonctions\n",
    "\\begin{align*}\n",
    "  \\widetilde{F} ~ \\colon \\quad \\mathbb{R}^{n} &\\to \\mathbb{R}\\\\\n",
    "  q &\\mapsto \\widetilde{F}(q) = \\frac{1}{3} \\langle q, r ~\\bullet~ q ~\\bullet~ \\vert q \\vert \\rangle + \\langle p_r, A_r q \\rangle\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "et\n",
    "\\begin{align*}\n",
    "  Q ~ \\colon \\quad  \\mathbb{R}^{n-m_d} &\\to \\mathbb{R}^{n}\\\\\n",
    "  q_c &\\mapsto Q(q_c) = q = q^{(0)} + B q_c\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "de telle sorte que\n",
    "\\begin{equation*}\n",
    "    F = \\widetilde{F} \\circ Q\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lemme :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etudions la dérivabilité de\n",
    "\n",
    "\\begin{align*}\n",
    "    f ~ \\colon \\quad \\mathbb{R} &\\to \\mathbb{R}\\\\\n",
    "    x &\\mapsto x \\vert x \\vert\n",
    "\\end{align*}\n",
    "\n",
    "Pour $x>0$, lorsque $h \\in \\mathbb{R}$ tend vers 0, $x+h$ devient et reste positif pour $h$ suffisamment petit de telle sorte que la dérivabilité de $f$ correspond à celle de $x \\mapsto x^2$.\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\forall x>0, \\quad f'(x) = 2x = 2 \\vert x \\vert\n",
    "\\end{equation*}\n",
    "\n",
    "De façon analogue, pour $x<0$, lorsque $h \\in \\mathbb{R}$ tend vers 0, $x+h$ devient et reste négatif pour $h$ suffisamment petit de telle sorte que la dérivabilité de $f$ correspond à celle de $x \\mapsto -x^2$.\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\forall x<0, \\quad f'(x) = -2x = 2 \\vert x \\vert\n",
    "\\end{equation*}\n",
    "\n",
    "Enfin pour $x=0$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{f(h) - f(0)}{h} = \\frac{h \\vert h \\vert}{h} = \\vert h \\vert \\xrightarrow[h \\to 0]{} 0 \\quad \\textit{ie} \\quad f'(0) = 0 = 2 \\vert 0 \\vert \n",
    "\\end{equation*}\n",
    "\n",
    "On en déduit\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\forall x \\in \\mathbb{R}, \\quad f'(x) = 2 \\vert x \\vert\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, on en montre que la fonction\n",
    "\n",
    "\\begin{align*}\n",
    "    g ~ \\colon \\quad \\mathbb{R} &\\to \\mathbb{R}\\\\\n",
    "    x &\\mapsto x^2 \\vert x \\vert\n",
    "\\end{align*}\n",
    "\n",
    "est dérivable sur $\\mathbb{R}$ de dérivée\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\forall x \\in \\mathbb{R}, \\quad g'(x) = 3x \\vert x \\vert\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Matrice jacobienne / gradient de $\\widetilde{F}$ :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour $q \\in \\mathbb{R}^{n}$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\widetilde{F}(q) = \\frac{1}{3} \\sum_{i = 1}^{n} r_i q_i^2 \\vert q_i \\vert + \\sum_{i = 1}^{m_r} (p_r)_i \\sum_{j = 1}^{n} (A_r)_{i,j} q_j\n",
    "\\end{equation*}\n",
    "\n",
    "Pour tout $1 \\leq k \\leq n$ et $q \\in \\mathbb{R}^{n}$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial \\widetilde{F}}{\\partial q_k}(q) = r_k q_k \\vert q_k \\vert + \\sum_{i = 1}^{m_r} (p_r)_i (A_r)_{i,k} = r_k q_k \\vert q_k \\vert + \\sum_{i = 1}^{m_r} (A_r)_{k, i}^T (p_r)_i\n",
    "\\end{equation*}\n",
    "\n",
    "de telle sorte que la matrice jacobienne $J_{\\widetilde{F}}$ et le gradient $\\nabla \\widetilde{F}$ de $\\widetilde{F}$ sont tels que\n",
    "\n",
    "\\begin{equation*}\n",
    "    J_{\\widetilde{F}}(q) = (\\nabla \\widetilde{F}(q))^T \\quad \\text{et} \\quad \\nabla \\widetilde{F}(q) = r ~\\bullet~ q ~\\bullet~ \\vert q \\vert + A_r^T p_r\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Matrice jacobienne de $Q$ :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tout $1 \\leq k \\leq n$, $1 \\leq j \\leq n - m_d$ et $q_c \\in \\mathbb{R}^{n-m_d}$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial Q_k}{\\partial (q_c)_j}(q_c) = B_{k,j}\n",
    "\\end{equation*}\n",
    "\n",
    "de telle sorte que la matrice jacobienne $J_{Q}$ de $Q$ est telle que\n",
    "\n",
    "\\begin{equation*}\n",
    "    J_Q(q_c) = B\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gradient de $F$ :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, par théorème de dérivation de fonctions composées,\n",
    "pour tout $1 \\leq j \\leq n - m_d$ et $q_c \\in \\mathbb{R}^{n-m_d}$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial F}{\\partial (q_c)_j}(q_c) = \\sum_{k = 1}^{n} \\frac{\\partial \\widetilde{F}}{\\partial q_k}(q) \\frac{\\partial Q_k}{\\partial (q_c)_j}(q_c) = \\sum_{k = 1}^{n} \\left( r_k q_k \\vert q_k \\vert + \\sum_{i = 1}^{m_r} (A_r)_{k, i}^T (p_r)_i \\right) B_{k,j} = \\sum_{k = 1}^{n} B_{j,k}^T (\\nabla \\widetilde{F}(q))_k = (B^T \\nabla \\widetilde{F}(q))_j\n",
    "\\end{equation*}\n",
    "\n",
    "où $q = Q(q_c) = q^{(0)} + B q_c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en déduit ainsi\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\nabla F(q_c) = B^T \\nabla \\widetilde{F}(Q(q_c))\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.b. Implémentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Probleme_R.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Probleme_R.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#############################################################################\n",
    "#                                                                           #\n",
    "#        DONNEES ASSOCIEES A LA RESOLUTION DES EQUATIONS D'UN RESEAU        #\n",
    "#                                                                           #\n",
    "#        Probleme_R : reseau representant un cas relativement realiste      #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "# Variables du probleme\n",
    "#\n",
    "# nom  : nom du reseau\n",
    "#\n",
    "# n    : nombre total d'arcs\n",
    "# m    : nombre total de noeuds\n",
    "# mr   : nombre de noeuds de type reservoir\n",
    "# md   : nombre de noeuds de type demande (= m-mr)\n",
    "#\n",
    "# orig : vecteur des numeros des noeuds initiaux des arcs : M(1,n)\n",
    "# dest : vecteur des numeros des noeuds finaux   des arcs : M(1,n)\n",
    "# absn : vecteur des abscisses des noeuds                 : M(1,m)\n",
    "# ordn : vecteur des ordonnees des noeuds                 : M(1,m)\n",
    "#\n",
    "# r    : vecteur des resistances des arcs                 : M(n,1)\n",
    "# pr   : vecteur des pressions des noeuds reservoirs      : M(mr,1)\n",
    "# fd   : vecteur des flux des noeuds de demande           : M(md,1)\n",
    "\n",
    "##### Nom du reseau\n",
    "\n",
    "nom = 'Realiste'\n",
    "\n",
    "##### Dimensions du reseau\n",
    "\n",
    "# Nombre de noeuds et d'arcs\n",
    "n = 22\n",
    "m = 16\n",
    "mr = 3\n",
    "md = m - mr\n",
    "\n",
    "##### Caracteristiques des noeuds et des arcs\n",
    " \n",
    "# Numeros des noeuds initiaux et finaux des arcs\n",
    "orig = np.array([1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 13, 1, 2, 4, 5, 7, 8, 14, 2, 10])\n",
    "dest = np.array([4, 16, 15, 5, 6, 10, 16, 9, 12, 10, 11, 14, 15, 16, 6, 8, 9, 11, 13, 15, 4, 13])\n",
    "\n",
    "orig = orig - 1 # car Python commence a 0\n",
    "dest = dest - 1 # car Python commence a 0\n",
    "\n",
    "# Coordonnees des noeuds\n",
    "absn = np.array([11, 18, 38, 4, 8, 15, 26, 4, 10, 19, 26, 7, 21, 33, 33, 16])\n",
    "ordn = np.array([28, 21, 8, 21, 17, 17, 26, 9, 13, 13, 18, 4, 9, 18, 12, 24])\n",
    "\n",
    "# Resistances des arcs\n",
    "r = np.array([100, 10, 1000, 100, 100, 10, 1000, 100, 1000, 100, 1000, 1000, 1000, 10, 10, 100 , 100, 1000, 100, 1000, 100, 10])\n",
    "\n",
    "# Pressions au pied des reservoirs (en m)\n",
    "pr = np.array([105, 104, 110])\n",
    "\n",
    "# Flux aux noeuds de demande (en m3/s)\n",
    "fd = np.array([+0.08, -1.30, +0.13, +0.09, +0.16, +0.14, +0.12, +0.07, +0.17, +0.11, +0.25, +0.01, +0.13])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Structures_N.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Stuctures_N.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "from numpy import dot\n",
    "\n",
    "###############################################################################\n",
    "#                                                                             #\n",
    "#  STRUCTURES DE DONNEES NECESSAIRES A LA RESOLUTION DES EQUATIONS DU RESEAU  #\n",
    "#                                                                             #\n",
    "#  Structures_N : matrices normales                                           #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "# Matrices issues de la topologie du reseau\n",
    "#\n",
    "# A    : matrice d'incidence noeuds-arcs du graphe        : M(m,n)\n",
    "# Ar   : sous-matrice de A correspondant aux reservoirs   : M(mr,n)\n",
    "# Ad   : sous-matrice complementaire de Ar pour A         : M(md,n)\n",
    "# AdT  : plus grande sous-matrice carree inversible de Ad : M(md,md)\n",
    "# AdI  : matrice inverse de AdT                           : M(md,md)\n",
    "# AdC  : sous-matrice complementaire de AdT pour Ad       : M(md,n-md)\n",
    "# B    : matrice d'incidence arcs-cycles du graphe        : M(n,n-md)\n",
    "#\n",
    "# Debit admissible\n",
    "#\n",
    "# q0   : vecteur des debits admissibles des arcs          : M(n,1)\n",
    "\n",
    "##### Matrice d'incidence et sous-matrices associees\n",
    "\n",
    "# Matrice d'incidence noeuds-arcs du graphe\n",
    "A = np.zeros((m, n))\n",
    "for i in range(m):\n",
    "    A[i, orig == i] = -1\n",
    "    A[i, dest == i] = +1\n",
    "\n",
    "# Partition de A suivant le type des noeuds\n",
    "Ar = A[:mr,:]\n",
    "Ad = A[mr:m,:]\n",
    "\n",
    "# Sous-matrice de Ad associee a un arbre et inverse\n",
    "AdT = Ad[:,:md]\n",
    "AdI = inv(AdT)\n",
    "\n",
    "# Sous matrice de Ad associee a un coarbre\n",
    "AdC = Ad[:,md:n]\n",
    "\n",
    "# Matrice d'incidence arcs-cycles\n",
    "B = np.zeros((n, n-md))\n",
    "B[:md,:] = -dot(AdI, AdC)\n",
    "B[md:,:] = np.eye(n-md)\n",
    "\n",
    "##### Vecteur des debits admissibles\n",
    "q0 = np.zeros(n)\n",
    "q0[:md] = dot(AdI,fd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Oracle Gradient :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def F(q):\n",
    "    return 1/3*np.dot(q,r*q*np.absolute(q)) + np.dot(pr,np.matmul(Ar,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Q(qc):\n",
    "    return q0+np.matmul(B,qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_F_tilde(q):\n",
    "    return r*q*np.absolute(q) + np.matmul(np.transpose(Ar),pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def G(qc):\n",
    "    return np.matmul(np.transpose(B),gradient_F_tilde(Q(qc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OraclePG(qC,ind):\n",
    "    if (ind == 2):\n",
    "        return((F(Q(qC)), None, ind))\n",
    "    elif (ind == 3):\n",
    "        return((None, G(qC), ind))\n",
    "    elif (ind == 4):\n",
    "        return((F(Q(qC)), G(qC), ind))\n",
    "    else:\n",
    "        print('la valeur de ind ne correspond à aucune entrée possible')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Gradient_F.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Gradient_F.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import process_time\n",
    "from numpy.linalg import norm\n",
    "\n",
    "#############################################################################\n",
    "#                                                                           #\n",
    "#         RESOLUTION D'UN PROBLEME D'OPTIMISATION SANS CONTRAINTES          #\n",
    "#                                                                           #\n",
    "#         Methode du gradient a pas fixe                                    #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "from Visualg import Visualg\n",
    "\n",
    "def Gradient_F(Oracle, x0):\n",
    "\n",
    "    ##### Initialisation des variables\n",
    "\n",
    "    iter_max = 10000\n",
    "    gradient_step = 0.0005\n",
    "    threshold = 0.000001\n",
    "\n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "\n",
    "    time_start = process_time()\n",
    "\n",
    "    x = x0\n",
    "    \n",
    "    ind = 4\n",
    "\n",
    "    ##### Boucle sur les iterations\n",
    "\n",
    "    for k in range(iter_max):\n",
    "\n",
    "        # Valeur du critere et du gradient\n",
    "        critere, gradient, ind = Oracle(x, ind)\n",
    "\n",
    "        # Test de convergence\n",
    "        gradient_norm = norm(gradient)\n",
    "        if gradient_norm <= threshold:\n",
    "            break\n",
    "\n",
    "        # Direction de descente\n",
    "        D = -gradient\n",
    "\n",
    "        # Mise a jour des variables\n",
    "        x = x + (gradient_step*D)\n",
    "\n",
    "        # Evolution du gradient, du pas, et du critere\n",
    "        gradient_norm_list.append(gradient_norm)\n",
    "        gradient_step_list.append(gradient_step)\n",
    "        critere_list.append(critere)\n",
    "\n",
    "    ##### Resultats de l'optimisation\n",
    "\n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient\n",
    "    x_opt = x\n",
    "    time_cpu = process_time() - time_start\n",
    "\n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "\n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "\n",
    "    return critere_opt, gradient_opt, x_opt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Verification.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Verification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import dot, transpose as t\n",
    "\n",
    "##############################################################################\n",
    "#                                                                            #\n",
    "#  VERIFICATION DES EQUATIONS D'EQUILIBRE D'UN RESEAU DE DISTRIBUTION D'EAU  #\n",
    "#                                                                            #\n",
    "##############################################################################\n",
    "\n",
    "# On suppose determinee la solution du probleme d'optimisation et reconstituee\n",
    "# les variables hydrauliques du reseau. On calcule le plus grand ecart sur les\n",
    "# 2 series d'equations qui caracterisent l'equilibre du reseau.\n",
    "#\n",
    "# Variables en entree\n",
    "#\n",
    "#    - q : vecteur des debits des arcs\n",
    "#    - z : vecteur des pertes de charge des arcs\n",
    "#    - f : vecteur des flux aux noeuds\n",
    "#    - p : vecteur des pressions aux noeuds\n",
    "\n",
    "def Verification(q, z, f, p):\n",
    "    \n",
    "    # Ecarts maximaux sur les lois de Kirschoff\n",
    "    tol_debits = max(abs(dot(A, q) - f))\n",
    "    tol_pression = max(abs(dot(t(A), p) + z))\n",
    "    \n",
    "    # Affichage\n",
    "    print()\n",
    "    print(\"Vérification des équations d'équilibre du réseau\")\n",
    "    print(\"Sur les débits : {}\".format(tol_debits))\n",
    "    print(\"Sur les pressions : {}\".format(tol_pression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Monitor_Skel.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Monitor_Skel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#                                                                           #\n",
    "#  MONITEUR D'ENCHAINEMENT POUR LE CALCUL DE L'EQUILIBRE D'UN RESEAU D'EAU  #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "# Verification des resultats\n",
    "from HydrauliqueP import HydrauliqueP\n",
    "from HydrauliqueD import HydrauliqueD\n",
    "\n",
    "##### Initialisation de l'algorithme\n",
    "\n",
    "# primal\n",
    "x0 = 0.1 * np.random.normal(size=n-md)\n",
    "\n",
    "# dual\n",
    "# x0 = 100 + np.random.normal(size=md)\n",
    "\n",
    "##### Minimisation proprement dite\n",
    "\n",
    "# gradient a pas fixe\n",
    "print()\n",
    "print(\"ALGORITHME DU GRADIENT A PAS FIXE\")\n",
    "copt, gopt, xopt = Gradient_F(OraclePG, x0)\n",
    "\n",
    "#gradient a pas variable\n",
    "# print()\n",
    "# print(\"ALGORITHME DU GRADIENT A PAS VARIABLE\")\n",
    "# copt, gopt, xopt = Gradient_V(OraclePG, x0)\n",
    "\n",
    "\n",
    "##### Verification des resultats\n",
    "\n",
    "# primal\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt)\n",
    "\n",
    "# dual\n",
    "# qopt, zopt, fopt, popt = HydrauliqueD(xopt)\n",
    "\n",
    "Verification(qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentaires :** la valeur optimale du critère vaut -3,734. Elle est obtenue au bout de 4054 iterations, pour un temps CPU de 0.08s. On observe bien une décroissance progressive de la norme du gradient au fur des itérations. Enfin, la vérification des équations d'équilibre du réseau est cohérente : les écarts sur les débits sont de l'ordre de $10^{-16}$ et ceux sur les pressions de l'ordre de $10^{-6}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.3. Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.a. Quelques éléments de calculs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Matrice hessienne de F :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tout $1 \\leq j \\leq n - m_d$ et $q_c \\in \\mathbb{R}^{n-m_d}$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial F}{\\partial (q_c)_j}(q_c) = \\sum_{k = 1}^{n} \\left( r_k q_k \\vert q_k \\vert + \\sum_{i = 1}^{m_r} (A_r)_{k, i}^T (p_r)_i \\right) B_{k,j} =\n",
    "    \\sum_{k = 1}^{n} \\left( r_k (Q(q_c))_k \\vert (Q(q_c))_k \\vert + \\sum_{i = 1}^{m_r} (A_r)_{k, i}^T (p_r)_i \\right) B_{k,j}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or pour tout $1 \\leq k \\leq n$, $1 \\leq i \\leq n - m_d$ et $q_c \\in \\mathbb{R}^{n-m_d}$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial (Q \\vert Q \\vert (q_c))_k}{\\partial (q_c)_i}(q_c) = 2 \\vert (Q (q_c))_k \\vert  \\frac{\\partial (Q(q_c))_k}{\\partial (q_c)_i}(q_c) = 2 \\vert (Q (q_c))_k \\vert  B_{k,i} = \\vert q_k \\vert  B_{k,i}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en déduit pour tout $1 \\leq i, ~ j \\leq n - m_d$ et $q_c \\in \\mathbb{R}^{n-m_d}$\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial^2 F}{\\partial (q_c)_i \\partial (q_c)_j}(q_c) =\n",
    "    \\sum_{k = 1}^{n} \\left( 2 r_k \\vert q_k \\vert   B_{k,i} B_{k,j} \\right) = 2 \\sum_{k = 1}^{n} r_k \\vert q_k \\vert B_{k,i} B_{k,j}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, on obtient l'expression suivante pour la matrice Hessienne de F en qc :\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\nabla^2{F}(q_c) = 2 ~ B^{T} ~ \\text{Diag}(r \\bullet \\vert q \\vert) ~ B\n",
    "    = 2 ~ B^{T} ~  \\text{Diag}(r \\bullet \\vert Q(q_c) \\vert) ~ B\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.b. Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def H(qc):\n",
    "    return 2*np.matmul(np.transpose(B), np.matmul(np.diag(r*np.absolute(Q(qc))), B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OraclePH(qC,ind):\n",
    "    if (ind == 2):\n",
    "        return((F(Q(qC)), None, None, ind))\n",
    "    elif (ind == 3):\n",
    "        return((None, G(qC), None, ind))\n",
    "    elif (ind == 4):\n",
    "        return((F(Q(qC)), G(qC), None, ind))\n",
    "    elif (ind == 5):\n",
    "        return((None, None, H(qC), ind))\n",
    "    elif (ind == 6):\n",
    "        return((None, G(qC), H(qC), ind))\n",
    "    elif (ind == 7):\n",
    "        return((F(Q(qC)), G(qC), H(qC), ind))\n",
    "    else:\n",
    "        print('la valeur de ind ne correspond à aucune entrée possible')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Newton_F.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Newton_F.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "#############################################################################\n",
    "#                                                                           #\n",
    "#         RESOLUTION D'UN PROBLEME D'OPTIMISATION SANS CONTRAINTES          #\n",
    "#                                                                           #\n",
    "#         Methode de Newton a pas fixe                                      #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "def Newton_F(Oracle, x0):\n",
    "    \n",
    "    ##### Initialisation des variables    \n",
    "    \n",
    "    iter_max = 100\n",
    "    gradient_step = 1\n",
    "    threshold = 0.000001\n",
    "    \n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "\n",
    "    time_start = process_time()\n",
    "    \n",
    "    x = x0\n",
    "    \n",
    "    ind = 7\n",
    "\n",
    "    ##### Boucle sur les iterations\n",
    "    \n",
    "    for k in range(iter_max):\n",
    "        \n",
    "        # Valeur du critere et du gradient\n",
    "        critere, gradient, hessien, ind = Oracle(x, ind)\n",
    "\n",
    "        # Test de convergence\n",
    "        gradient_norm = norm(gradient)\n",
    "        if gradient_norm <= threshold:\n",
    "            break\n",
    "        \n",
    "        # Direction de descente\n",
    "        D = - dot(inv(hessien), gradient)\n",
    "        \n",
    "        # Mise a jour des variables\n",
    "        x = x + (gradient_step*D)\n",
    "        \n",
    "        # Evolution du gradient, du pas, et du critere\n",
    "        gradient_norm_list.append(gradient_norm)\n",
    "        gradient_step_list.append(gradient_step)\n",
    "        critere_list.append(critere)\n",
    "   \n",
    "    ##### Resultats de l'optimisation\n",
    "    \n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient\n",
    "    x_opt = x\n",
    "    time_cpu = process_time() - time_start\n",
    "\n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "    \n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "    \n",
    "    return critere_opt, gradient_opt, x_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Monitor_Skel.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#                                                                           #\n",
    "#  MONITEUR D'ENCHAINEMENT POUR LE CALCUL DE L'EQUILIBRE D'UN RESEAU D'EAU  #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "# Verification des resultats\n",
    "#from HydrauliqueP import HydrauliqueP\n",
    "#from HydrauliqueD import HydrauliqueD\n",
    "\n",
    "##### Initialisation de l'algorithme\n",
    "\n",
    "# primal\n",
    "x0 = 0.1 * np.random.normal(size=n-md)\n",
    "\n",
    "\n",
    "##### Minimisation proprement dite\n",
    "\n",
    "# Newton a pas fixe\n",
    "print()\n",
    "print(\"ALGORITHME DE NEWTON A PAS FIXE\")\n",
    "copt, gopt, xopt = Newton_F(OraclePH, x0)\n",
    "\n",
    "\n",
    "##### Verification des resultats\n",
    "\n",
    "# primal\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt)\n",
    "\n",
    "\n",
    "Verification(qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentaires :** on retrouve bien la même valeur optimale du critère : -3,734. Elle est cette fois-ci obtenue au bout de 6 iterations seulement, pour un temps CPU de 0.003s. Par rapport à la descente de gradient à pas fixe, Newton gagne un facteur 20 en terme de temps de calcul. On observe bien une décroissance progressive de la norme du gradient au fur des itérations. Enfin, la vérification des équations d'équilibre du réseau est cohérente : les écarts sur les débits sont de l'ordre de $10^{-16}$ et ceux sur les pressions de l'ordre de $10^{-10}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise les notations de l'énoncé. On suppose la matrice $A$ et les vecteurs $f_d$ et $p_r$ connus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\bf{(13)} \\Leftrightarrow \\bf{(14)} :$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour $q \\in \\mathbb{R}^n$ et $f_r \\in \\mathbb{R}^{m_r}$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    Aq - f = 0\n",
    "    \\qquad \\Leftrightarrow \\qquad\n",
    "    \\begin{pmatrix}\n",
    "        A_r \\\\\n",
    "        A_d\n",
    "    \\end{pmatrix}\n",
    "    q -\n",
    "    \\begin{pmatrix}\n",
    "        f_r \\\\\n",
    "        f_d\n",
    "    \\end{pmatrix}\n",
    "    = 0\n",
    "    \\qquad \\Leftrightarrow \\qquad\n",
    "    \\begin{cases}\n",
    "        f_r = A_r q \\\\\n",
    "        A_d q - f_d = 0 \n",
    "    \\end{cases}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autrement dit, $f_r$, vérifiant avec $q$ l'égalité à gauche, est entièrement déterminée par $q$. On en déduit que l'ensemble des valeurs prise par le critère du problème (13) peut s'exprimer qu'en fonction de $q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    & \\{ ~\n",
    "    \\frac{1}{3} \\langle q, r ~\\bullet~ q ~\\bullet~ \\vert q \\vert \\rangle + \\langle p_r, f_r \\rangle\n",
    "    ~ \\vert ~\n",
    "    q \\in \\mathbb{R}^n, ~ f_r \\in \\mathbb{R}^{m_r}, ~ Aq - f = 0 \n",
    "    ~ \\} \\\\\n",
    "    = ~\n",
    "    & \\{ ~\n",
    "    \\frac{1}{3} \\langle q, r ~\\bullet~ q ~\\bullet~ \\vert q \\vert \\rangle + \\langle p_r, A_r q \\rangle\n",
    "    ~ \\vert ~\n",
    "    q \\in \\mathbb{R}^n, ~ A d_q - f_d = 0 \n",
    "    ~ \\}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les ensembles ci-dessus étant égaux, ils possèdent un même minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On en déduit l'équivalence entre les problèmes (13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "    & \\underset{q \\in \\mathbb{R}^n, ~ f_r \\in \\mathbb{R}^{m_r}}{\\text{min}}\n",
    "    & & \\frac{1}{3} \\langle q, r ~\\bullet~ q ~\\bullet~ \\vert q \\vert \\rangle + \\langle p_r, f_r \\rangle \\\\\n",
    "    & \\text{s.c.}\n",
    "    & & Aq - f = 0 \n",
    "    \\end{aligned}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "et (14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "    & \\underset{q \\in \\mathbb{R}^n}{\\text{min}}\n",
    "    & & \\frac{1}{3} \\langle q, r ~\\bullet~ q ~\\bullet~ \\vert q \\vert \\rangle + \\langle p_r, A_r q \\rangle \\\\\n",
    "    & \\text{s.c.}\n",
    "    & & A_d q - f_d = 0 \n",
    "    \\end{aligned}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\bf{(14)} \\Leftrightarrow \\bf{(19)} :$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour $q \\in \\mathbb{R}^n$ et $q_C \\in \\mathbb{R}^{n-m_d}$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    A_d q - f_d = 0\n",
    "    \\qquad \\Leftrightarrow \\qquad\n",
    "    \\begin{cases}\n",
    "    {\n",
    "        q =\n",
    "        \\begin{pmatrix}\n",
    "            q_T \\\\\n",
    "            q_C\n",
    "        \\end{pmatrix}\n",
    "    } \\\\\n",
    "    {\n",
    "        \\begin{pmatrix}\n",
    "            A_{d,T}  & A_{d,C}\n",
    "        \\end{pmatrix}\n",
    "        \\begin{pmatrix}\n",
    "            q_T \\\\\n",
    "            q_C\n",
    "        \\end{pmatrix}\n",
    "        - f_d = 0\n",
    "    }\n",
    "    \\end{cases}\n",
    "    \\qquad \\Leftrightarrow \\qquad\n",
    "    \\begin{cases}\n",
    "    {\n",
    "        q =\n",
    "        \\begin{pmatrix}\n",
    "            q_T \\\\\n",
    "            q_C\n",
    "        \\end{pmatrix}\n",
    "    } \\\\\n",
    "    {\n",
    "        q_T = A_{d,T}^{-1} (f_d - A_{d,C} q_C)\n",
    "    }\n",
    "    \\end{cases}\n",
    "    \\qquad \\Leftrightarrow \\qquad\n",
    "    q = q^{(0)} + B q_C\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autrement dit, $q \\in \\mathbb{R}^n$, vérifiant avec l'égalité à gauche, est entièrement déterminé par son vecteur induit $q_C \\in \\mathbb{R}^{n-m_d}$. On en déduit que l'ensemble des valeurs prise par le critère du problème (14) peut s'exprimer qu'en fonction de $q_c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    & \\{ ~\n",
    "    \\frac{1}{3} \\langle q, r ~\\bullet~ q ~\\bullet~ \\vert q \\vert \\rangle + \\langle p_r, A_r q \\rangle\n",
    "    ~ \\vert ~\n",
    "    q \\in \\mathbb{R}^n, ~ A d_q - f_d = 0 \n",
    "    ~ \\} \\\\\n",
    "    = ~\n",
    "    & \\{ ~\n",
    "    \\frac{1}{3} \\langle q^{(0)} + B q_C, r ~\\bullet~ (q^{(0)} + B q_C) ~\\bullet~ \\vert q^{(0)} + B q_C \\vert \\rangle\n",
    "    + \\langle p_r, A_r (q^{(0)} + B q_C) \\rangle\n",
    "    ~ \\vert ~\n",
    "    q_c \\in \\mathbb{R}^{n-m_d}\n",
    "    ~ \\}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les ensembles ci-dessus étant égaux, ils possèdent un même minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On en déduit l'équivalence entre les problèmes (14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "    & \\underset{q \\in \\mathbb{R}^n}{\\text{min}}\n",
    "    & & \\frac{1}{3} \\langle q, r ~\\bullet~ q ~\\bullet~ \\vert q \\vert \\rangle + \\langle p_r, A_r q \\rangle \\\\\n",
    "    & \\text{s.c.}\n",
    "    & & A_d q - f_d = 0 \n",
    "    \\end{aligned}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "et (19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "    \\underset{q_C \\in \\mathbb{R}^{n-m_d}}{\\text{min}} \\qquad\n",
    "    \\frac{1}{3} \\langle q^{(0)} + B q_C, r ~\\bullet~ (q^{(0)} + B q_C) ~\\bullet~ \\vert q^{(0)} + B q_C \\vert\n",
    "    \\rangle + \\langle p_r, A_r (q^{(0)} + B q_C) \\rangle\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Coercivité du critère (14) :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour $q \\in \\mathbb{R}^{n} \\setminus \\{0\\}$,\n",
    "\n",
    "Par Cauchy-Schwartz, <br>\n",
    "$\\langle p_r, A_r q \\rangle\n",
    "= \\langle A_r^T p_r, q \\rangle \\geq - \\| A_r^T p_r \\| \\| q \\|\n",
    "\\geq - \\| A_r^T p_r \\| \\sqrt{n} ~ \\underset{1 \\leq i \\leq n}{\\text{max}} \\vert q_i \\vert$\n",
    "\n",
    "et <br>\n",
    "$\\langle q, r ~\\bullet~ q ~\\bullet~ \\vert q \\vert \\rangle\n",
    "= \\sum_{i = 0}^{n} r_i q_i^2 \\vert q_i \\vert\n",
    "\\geq \\sum_{i = 0}^{n} \\underset{1 \\leq j \\leq n}{\\text{min}}(r_j) ~ q_i^2 \\vert q_i \\vert\n",
    "= \\underset{1 \\leq j \\leq n}{\\text{min}}(r_j) \\sum_{i = 0}^{n} q_i^2 \\vert q_i \\vert \n",
    "\\geq \\underset{1 \\leq j \\leq n}{\\text{min}}(r_j) ~ \\underset{1 \\leq i \\leq n}{\\text{max}}\\vert q_i \\vert^3 $\n",
    "\n",
    "d'où <br>\n",
    "$\\widetilde{F}(q) \\geq \\frac{1}{3} \\underset{1 \\leq j \\leq n}{\\text{min}}(r_j) ~ \n",
    "\\underset{1 \\leq i \\leq n}{\\text{max}}\\vert q_i \\vert^3 \n",
    "- \\| A_r^T p_r \\| \\sqrt{n} ~ \\underset{1 \\leq i \\leq n}{\\text{max}} \\vert q_i \\vert\n",
    "\\underset{\\| q \\| \\rightarrow + \\infty}{\\longrightarrow} + \\infty $\n",
    "\n",
    "Autrement dit $\\widetilde{F}$ est coercive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Existence de la solution au problème (14) :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme la fonction critère $\\widetilde{F}$ du problème (14) est continue coercive et que l'ensemble $U = \\{q \\in \\mathbb{R}^{n}, ~ A_d q - f_d = 0 \\}$ est fermé (puisque sous-espace vectoriel) non borné, on en déduit que le problème (14) admet au moins une solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convexité du critère (14) :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par la question 4.2, pour tout $1 \\leq i \\leq n$ et $q \\in \\mathbb{R}^{n}$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial \\widetilde{F}}{\\partial q_j}(q) = r_j q_j \\vert q_j \\vert + \\sum_{i = 1}^{m_r} (p_r)_i (A_r)_{i,j} = r_j q_j \\vert q_j \\vert + \\sum_{i = 1}^{m_r} (A_r)_{j, i}^T (p_r)_i\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tout $1 \\leq i, j \\leq n$ et $q \\in \\mathbb{R}^{n}$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial^2 \\widetilde{F}}{\\partial q_i \\partial q_j}(q) = \n",
    "    \\begin{cases}\n",
    "        2 r_i \\vert q_i \\vert \\quad \\text{si} \\quad i = j \\\\\n",
    "        0 \\quad \\text{sinon}\n",
    "    \\end{cases}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en déduit que pour $q \\in \\mathbb{R}^{n}$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\nabla^2{\\widetilde{F}}(q) = 2 ~ \\text{Diag}(r \\bullet \\vert q \\vert)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A $\\tilde{q} \\in \\mathbb{R}^{n} \\setminus \\{0\\}$ fixé, pour $q \\in \\mathbb{R}^{n} \\setminus \\{0\\}$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\langle q, \\nabla^2{\\widetilde{F}}(\\tilde{q}) ~ q \\rangle\n",
    "    = q^T ~ \\nabla^2{\\widetilde{F}}(\\tilde{q}) ~ q\n",
    "    = 2 \\sum_{i = 1}^{n} r_i \\vert \\tilde{q}_i \\vert q_i^2 > 0\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en déduit que le critère $\\widetilde{F}$ du problème (14) est strictement convexe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit $\\beta > 0$. <br>\n",
    "Prenons $\\tilde{q} \\in \\mathbb{R}^{n} \\setminus \\{0\\}$ tel que $~ \\tilde{q}_i < \\frac{\\beta}{2 \\underset{1 \\leq j \\leq n}{\\text{max}}(r_j)}$ pour tout $1 \\leq i \\leq n$, alors,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\langle q, \\nabla^2{\\widetilde{F}}(\\tilde{q}) ~ q \\rangle\n",
    "    = q^T ~ \\nabla^2{\\widetilde{F}}(\\tilde{q}) ~ q\n",
    "    = 2 \\sum_{i = 1}^{n} r_i \\vert \\tilde{q}_i \\vert q_i^2\n",
    "    < 2 \\sum_{i = 1}^{n} r_i \\frac{\\beta}{2 \\underset{1 \\leq j \\leq n}{\\text{max}}(r_j)} q_i^2 \\leq \\beta \\sum_{i = 1}^{n} q_i^2 = \\beta \\| q \\|^2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en déduit que le critère $\\widetilde{F}$ du problème (14) n'est pas fortement convexe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Unicité de la solution du problème (14) :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme le critère $\\widetilde{F}$ du problème (14) est strictement convexe et que l'ensemble $U = \\{q \\in \\mathbb{R}^{n}, ~ A_d q - f_d = 0 \\}$ est convexe (puisque sous-espace vectoriel), si (14) admet une solution, elle est unique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Racine d'une matrice diagonale :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posons pour $D = Diag(x) \\in \\mathbb{R}^{N \\times N}$ matrice diagonale obtenue à partir du vecteur positif $x = (x_i)_i \\in \\mathbb{R}+^{N}$, la matrice racine carrée $\\sqrt{D} = Diag(\\sqrt{x})  \\in \\mathbb{R}^{N \\times N}$, matrice diagonale obtenue à partir du vecteur positif $\\sqrt{x} = (\\sqrt{x_i})_i \\in \\mathbb{R}+^{N}$ des racines carrées des coordonnées de $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convexité du critère (19) :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par la question 4.3, pour $q_C \\in \\mathbb{R}^{n-m_d}$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "    \\nabla^2{F}(q_c) = 2 ~ B^{T} ~ \\text{Diag}(r \\bullet \\vert q \\vert) ~ B\n",
    "    = 2 ~ B^{T} ~  \\text{Diag}(r \\bullet \\vert Q(q_c) \\vert) ~ B\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A $\\tilde{q_C} \\in \\mathbb{R}^{n-m_d}$ fixé, pour $q_C \\in \\mathbb{R}^{n-m_d}$,\n",
    "\n",
    "\\begin{align*}\n",
    "    \\langle q_C, \\nabla^2{F}(\\tilde{q_C}) \\rangle\n",
    "    & = q_C^T ~ \\nabla^2{F}(\\tilde{q_C}) ~ q_C \\\\\n",
    "    & = 2 ~ q_C^T ~ B^T ~ \\sqrt{\\text{Diag} \\left(r \\bullet \\vert Q(\\tilde{q_c}) \\vert \\right)}^T ~~\n",
    "    \\sqrt{\\text{Diag} \\left(r \\bullet \\vert Q(\\tilde{q_c}) \\vert \\right)} ~ B ~ q_C \\\\\n",
    "    & = 2 ~ \\| \\sqrt{\\text{Diag} \\left(r \\bullet \\vert Q(\\tilde{q_c}) \\vert \\right)} ~ B ~ q_C \\| ^ 2 \\\\\n",
    "    & \\geq 0\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en déduit que critère $F$ du problème (19) est convexe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Séance de travaux pratiques 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On encode les deux règles de Wolfe ci-dessous (Wolfe1 et Wolfe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Wolfe1(alpha, x, xn, D, omega_1, Oracle):\n",
    "    ind = 4\n",
    "    critere_x, gradient_x, _ = Oracle(xp, ind)\n",
    "    critere_xn, gradient_xn, _ = Oracle(xn, ind)\n",
    "    return (omega_1*alpha*np.dot(gradient_xp, D) - critere_xn + critere_xp >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Wolfe2(alpha, x, xn, D, Oracle):\n",
    "    ind = 4\n",
    "    critere_x, gradient_x, _ = Oracle(xp, ind)\n",
    "    critere_xn, gradient_xn, _ = Oracle(xn, ind)\n",
    "    return (np.dot(gradient_xn, D) - omega_2*np.dot(gradient_x, D) >= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Wolfe_Skel.py :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On implémente ici l'algorithme de recherche linéaire suivant les conditions de Wolfe. <br>\n",
    "Il nous a fallu faire deux versions de la recherche suivant que l'Oracle passé en paramètre était OraclePG ou OraclePH, car le premier ne renvoie que 3 éléments (F, G, ind), tandis que le second en renvoie 4 (F, G, H, ind)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Wolfe_Skel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#                                                                      #\n",
    "#          RECHERCHE LINEAIRE SUIVANT LES CONDITIONS DE WOLFE          #\n",
    "#                                                                      #\n",
    "#          Algorithme de Fletcher-Lemarechal                           #\n",
    "#                                                                      #\n",
    "########################################################################\n",
    "\n",
    "#  Arguments en entree\n",
    "#\n",
    "#    alpha  : valeur initiale du pas\n",
    "#    x      : valeur initiale des variables\n",
    "#    D      : direction de descente\n",
    "#    Oracle : nom de la fonction Oracle\n",
    "#\n",
    "#  Arguments en sortie\n",
    "#\n",
    "#    alphan : valeur du pas apres recherche lineaire\n",
    "#    ok     : indicateur de reussite de la recherche \n",
    "#             = 1 : conditions de Wolfe verifiees\n",
    "#             = 2 : indistinguabilite des iteres\n",
    "\n",
    "def Wolfe(alpha, x, D, Oracle):\n",
    "    \n",
    "    ##### Coefficients de la recherche lineaire\n",
    "\n",
    "    omega_1 = 0.1 # c.f. methodes.pdf\n",
    "    omega_2 = 0.9 # c.f. methodes.pdf\n",
    "\n",
    "    alpha_min = 0\n",
    "    alpha_max = np.inf\n",
    "\n",
    "    ok = 0\n",
    "    dltx = 0.00000001\n",
    "    \n",
    "    ind = 4\n",
    "\n",
    "    ##### Algorithme de Fletcher-Lemarechal\n",
    "    \n",
    "    # Appel de l'oracle au point initial\n",
    "    critere_x, gradient_x, _ = Oracle(x, ind)\n",
    "    \n",
    "    # Initialisation de l'algorithme\n",
    "    alpha_n = alpha\n",
    "    xn = x\n",
    "    \n",
    "    # Boucle de calcul du pas\n",
    "    while ok == 0:\n",
    "        \n",
    "        # xn represente le point pour la valeur courante du pas,\n",
    "        # xp represente le point pour la valeur precedente du pas.\n",
    "        xp = xn\n",
    "        xn = x + alpha_n*D\n",
    "        \n",
    "        # Appel de l'oracle au point courant\n",
    "        critere_xn, gradient_xn, _ = Oracle(xn, ind)\n",
    "        \n",
    "        # Calcul des conditions de Wolfe\n",
    "        cond1 = (omega_1*alpha_n*np.dot(gradient_x, D) - critere_xn + critere_x >= 0)\n",
    "        cond2 = (np.dot(gradient_xn, D) - omega_2*np.dot(gradient_x, D) >= 0)\n",
    "        \n",
    "        # Test des conditions de Wolfe\n",
    "        # - si la condition 1 n'est pas verifiée\n",
    "        if (not cond1):\n",
    "            alpha_max = alpha_n\n",
    "            alpha_n = (alpha_min + alpha_max)/2\n",
    "        # - si la condition 1 est vérifiée et que la condition 2 ne l'est pas\n",
    "        elif (not cond2):\n",
    "            alpha_min = alpha_n\n",
    "            if alpha_max == np.inf:\n",
    "                alpha_n = 2*alpha_min\n",
    "            else:\n",
    "                alpha_n = (alpha_min + alpha_max)/2\n",
    "        # - si les deux conditions de Wolfe sont verifiées\n",
    "        else:\n",
    "            ok = 1\n",
    "        \n",
    "        # Test d'indistinguabilite\n",
    "        if np.linalg.norm(xn - xp) < dltx:\n",
    "            ok = 2\n",
    "\n",
    "    return alpha_n, ok\n",
    "\n",
    "\n",
    "# 2e Wolfe qui prend OraclePH et non plus OraclePG en paramètre\n",
    "def WolfePH(alpha, x, D, Oracle):\n",
    "\n",
    "    ##### Coefficients de la recherche lineaire\n",
    "\n",
    "    omega_1 = 0.1 # c.f. methodes.pdf\n",
    "    omega_2 = 0.9 # c.f. methodes.pdf\n",
    "\n",
    "    alpha_min = 0\n",
    "    alpha_max = np.inf\n",
    "\n",
    "    ok = 0\n",
    "    dltx = 0.00000001\n",
    "\n",
    "    ind = 7\n",
    "\n",
    "    ##### Algorithme de Fletcher-Lemarechal\n",
    "\n",
    "    # Appel de l'oracle au point initial\n",
    "    critere_x, gradient_x, _, _ = Oracle(x, ind)\n",
    "\n",
    "    # Initialisation de l'algorithme\n",
    "    alpha_n = alpha\n",
    "    xn = x\n",
    "\n",
    "    # Boucle de calcul du pas\n",
    "    while ok == 0:\n",
    "        #print('yes')\n",
    "\n",
    "        # xn represente le point pour la valeur courante du pas,\n",
    "        # xp represente le point pour la valeur precedente du pas.\n",
    "        xp = xn\n",
    "        xn = x + alpha_n*D\n",
    "\n",
    "        # Appel de l'oracle au point courant\n",
    "        critere_xn, gradient_xn, _, _ = Oracle(xn, ind)\n",
    "\n",
    "        # Calcul des conditions de Wolfe\n",
    "        cond1 = (omega_1*alpha_n*np.dot(gradient_x, D) - critere_xn + critere_x >= 0)\n",
    "        cond2 = (np.dot(gradient_xn, D) - omega_2*np.dot(gradient_x, D) >= 0)\n",
    "\n",
    "        # Test des conditions de Wolfe\n",
    "        # - si la condition 1 n'est pas verifiée\n",
    "        if (not cond1):\n",
    "            alpha_max = alpha_n\n",
    "            alpha_n = (alpha_min + alpha_max)/2\n",
    "        # - si la condition 1 est vérifiée et que la condition 2 ne l'est pas\n",
    "        elif (not cond2):\n",
    "            alpha_min = alpha_n\n",
    "            if alpha_max == np.inf:\n",
    "                alpha_n = 2*alpha_min\n",
    "            else:\n",
    "                alpha_n = (alpha_min + alpha_max)/2\n",
    "        # - si les deux conditions de Wolfe sont verifiées\n",
    "        else:\n",
    "            ok = 1\n",
    "\n",
    "        # Test d'indistinguabilite\n",
    "        if np.linalg.norm(xn - xp) < dltx:\n",
    "            ok = 2\n",
    "\n",
    "    return alpha_n, ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Gradient_V.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Gradient_V.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import process_time\n",
    "\n",
    "#############################################################################\n",
    "#                                                                           #\n",
    "#         RESOLUTION D'UN PROBLEME D'OPTIMISATION SANS CONTRAINTES          #\n",
    "#                                                                           #\n",
    "#         Methode du gradient a pas variable                                #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "def Gradient_V(Oracle, x0):\n",
    "\n",
    "    ##### Initialisation des variables\n",
    "\n",
    "    iter_max = 10000\n",
    "    threshold = 0.000001\n",
    "\n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "\n",
    "    time_start = process_time()\n",
    "\n",
    "    x = x0\n",
    "\n",
    "    ##### Boucle sur les iterations\n",
    "\n",
    "    for k in range(iter_max):\n",
    "\n",
    "        # Valeur du critere et du gradient\n",
    "        critere, gradient, ind = Oracle(x, 4)\n",
    "\n",
    "        # Test de convergence\n",
    "        gradient_norm = norm(gradient)\n",
    "        if gradient_norm <= threshold:\n",
    "            break\n",
    "\n",
    "        # Direction de descente\n",
    "        D = -gradient\n",
    "\n",
    "        # Mise a jour des variables\n",
    "        gradient_step = 1 # Trouver un meilleur coefficient\n",
    "        gradient_step, _ = Wolfe(gradient_step, x, D, Oracle)\n",
    "        x = x + (gradient_step*D)\n",
    "\n",
    "        # Evolution du gradient, du pas, et du critere\n",
    "        gradient_norm_list.append(gradient_norm)\n",
    "        #gradient_norm_list.append(np.log10(gradient_norm))\n",
    "        gradient_step_list.append(gradient_step)\n",
    "        critere_list.append(critere)\n",
    "\n",
    "    ##### Resultats de l'optimisation\n",
    "\n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient\n",
    "    x_opt = x\n",
    "    time_cpu = process_time() - time_start\n",
    "\n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "\n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "\n",
    "    return critere_opt, gradient_opt, x_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Monitor_Skel.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#                                                                           #\n",
    "#  MONITEUR D'ENCHAINEMENT POUR LE CALCUL DE L'EQUILIBRE D'UN RESEAU D'EAU  #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "# Verification des resultats\n",
    "#from HydrauliqueP import HydrauliqueP\n",
    "#from HydrauliqueD import HydrauliqueD\n",
    "\n",
    "##### Initialisation de l'algorithme\n",
    "\n",
    "# primal\n",
    "x0 = 0.1 * np.random.normal(size=n-md)\n",
    "\n",
    "##### Minimisation proprement dite\n",
    "\n",
    "# Gradient a pas variable\n",
    "print()\n",
    "print(\"ALGORITHME DE GRADIENT A PAS VARIABLE\")\n",
    "copt, gopt, xopt = Gradient_V(OraclePG, x0)\n",
    "\n",
    "\n",
    "##### Verification des resultats\n",
    "\n",
    "# primal\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt)\n",
    "\n",
    "\n",
    "Verification(qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentaires :** on retrouve la aussi la même valeur optimale du critère : -3,734. Elle est obtenue au bout de 293 iterations, pour un temps CPU de 0.09s. Bien que le nombre d'itérations soit bien inferieur à celui de la méthode à pas fixe, cette descente de gradient à pas variable est aussi couteuse en temps de calcul. On observe bien une décroissance progressive globale de la norme du gradient au cours de itérations. On voit aussi comment le pas de gradient varie au cours de itérations. Enfin, la vérification des équations d'équilibre du réseau est cohérente : les écarts sur les débits sont de l'ordre de $10^{-16}$ et ceux sur les pressions de l'ordre de $10^{-6}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1. Polak Ribière"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Polak_Ribiere.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Polak_Ribiere.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#                                                                           #\n",
    "#         RESOLUTION D'UN PROBLEME D'OPTIMISATION SANS CONTRAINTES          #\n",
    "#                                                                           #\n",
    "#         Methode de gradient conjugue : Polak-Ribiere                      #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "#from Visualg import Visualg\n",
    "#from Wolfe_Skel import Wolfe\n",
    "\n",
    "def Polak_Ribiere(Oracle, x0):\n",
    "\n",
    "    ##### Initialisation des variables\n",
    "\n",
    "    iter_max = 10000\n",
    "    threshold = 0.000001\n",
    "\n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "\n",
    "    Id = np.identity(x0.size)\n",
    "\n",
    "    time_start = process_time()\n",
    "\n",
    "    ##### Premiere iteration\n",
    "\n",
    "    # Point de depart\n",
    "    xp = x0\n",
    "\n",
    "    # Valeur du critere et du gradient\n",
    "    ind = 4\n",
    "    critere, gradient_p, _ = Oracle(xp, ind)\n",
    "\n",
    "    # Direction de descente\n",
    "    D = -gradient_p\n",
    "\n",
    "    # Pas du gradient par recherche linéaire\n",
    "    gradient_step = 1 # Trouver un meilleur coefficient\n",
    "    gradient_step, _ = Wolfe(gradient_step, xp, D, Oracle)\n",
    "\n",
    "    # Point suivant\n",
    "    xn = xp + (gradient_step*D)\n",
    "\n",
    "    # Evolution du gradient, du pas, et du critere\n",
    "    gradient_norm_list.append(norm(gradient_p))\n",
    "    gradient_step_list.append(gradient_step)\n",
    "    critere_list.append(critere)\n",
    "\n",
    "    ##### Boucle sur les iterations\n",
    "\n",
    "    for k in range(iter_max):\n",
    "\n",
    "        # Valeur du critere et du gradient\n",
    "        critere, gradient_n, _ = Oracle(xn, ind)\n",
    "\n",
    "        # Test de convergence\n",
    "        gradient_norm = norm(gradient_n)\n",
    "        if gradient_norm <= threshold:\n",
    "            break\n",
    "\n",
    "        # Valeur du coefficient de Polak_Ribiere\n",
    "        delta_g = gradient_n - gradient_p\n",
    "        beta_n = np.dot(gradient_n, delta_g)/np.dot(gradient_p, gradient_p)\n",
    "\n",
    "        # Direction de descente\n",
    "        D = -gradient_n + beta_n*D\n",
    "\n",
    "        # Pas du gradient par recherche linéaire\n",
    "        gradient_step = 1 # Trouver un meilleur coefficient\n",
    "        gradient_step, _ = Wolfe(gradient_step, xn, D, Oracle)\n",
    "\n",
    "        # Mise a jour des variables\n",
    "        xp = xn\n",
    "        gradient_p = gradient_n\n",
    "        xn = xp + (gradient_step*D)\n",
    "\n",
    "        # Evolution du gradient, du pas, et du critere\n",
    "        gradient_norm_list.append(gradient_norm)\n",
    "        gradient_step_list.append(gradient_step)\n",
    "        critere_list.append(critere)\n",
    "\n",
    "    ##### Resultats de l'optimisation\n",
    "\n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient_n\n",
    "    x_opt = xn\n",
    "    time_cpu = process_time() - time_start\n",
    "\n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "\n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "\n",
    "    return critere_opt, gradient_opt, x_opt\n",
    "\n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "\n",
    "    return critere_opt, gradient_opt, x_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Monitor_Skel.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#                                                                           #\n",
    "#  MONITEUR D'ENCHAINEMENT POUR LE CALCUL DE L'EQUILIBRE D'UN RESEAU D'EAU  #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "# Verification des resultats\n",
    "#from HydrauliqueP import HydrauliqueP\n",
    "#from HydrauliqueD import HydrauliqueD\n",
    "\n",
    "##### Initialisation de l'algorithme\n",
    "\n",
    "# primal\n",
    "x0 = 0.1 * np.random.normal(size=n-md)\n",
    "\n",
    "##### Minimisation proprement dite\n",
    "\n",
    "# Gradient Polak-Ribiere \n",
    "print()\n",
    "print(\"ALGORITHME DE GRADIENT POLAK-RIBIERE\")\n",
    "copt, gopt, xopt = Polak_Ribiere(OraclePG, x0)\n",
    "\n",
    "\n",
    "##### Verification des resultats\n",
    "\n",
    "# primal\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt)\n",
    "\n",
    "\n",
    "Verification(qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentaires :** on retrouve la valeur optimale du critère : -3,734. Elle est obtenue au bout de 195 iterations, pour un temps CPU de 0.06s, ce qui constitue une amélioration de l'ordre de 30% par rapport aux méthodes de descente de gradient (à pas fixe comme à pas variable). On observe bien une décroissance progressive globale de la norme du gradient au cours de itérations, tout comme les variations du pas de gradient. Enfin, la vérification des équations d'équilibre du réseau est cohérente : les écarts sur les débits sont de l'ordre de $10^{-16}$ et ceux sur les pressions de l'ordre de $10^{-7}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2. BFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier BFGS.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load BFGS.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#                                                                           #\n",
    "#         RESOLUTION D'UN PROBLEME D'OPTIMISATION SANS CONTRAINTES          #\n",
    "#                                                                           #\n",
    "#         Methode BFGS Inverse                                              #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "#from Visualg import Visualg\n",
    "#from Wolfe_Skel import Wolfe\n",
    "\n",
    "def BFGS(Oracle, x0):\n",
    "\n",
    "    ##### Initialisation des variables\n",
    "\n",
    "    iter_max = 10000\n",
    "    threshold = 0.000001\n",
    "\n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "    \n",
    "    Id = np.identity(x0.size)\n",
    "\n",
    "    time_start = process_time()\n",
    "\n",
    "    \n",
    "    ##### Premiere iteration\n",
    "    \n",
    "    # Point de depart\n",
    "    xp = x0\n",
    "    \n",
    "    # Valeur du critere et du gradient\n",
    "    ind = 4\n",
    "    critere, gradient_p, _ = Oracle(xp, ind)\n",
    "    \n",
    "    # Valeur de l'approximation de l'inverse de la Hessienne\n",
    "    Wp = Id\n",
    "    \n",
    "    # Direction de descente\n",
    "    D = -gradient_p\n",
    "    \n",
    "    # Pas du gradient par recherche linéaire\n",
    "    gradient_step = 1 # Trouver un meilleur coefficient\n",
    "    gradient_step, _ = Wolfe(gradient_step, xp, D, Oracle)\n",
    "    \n",
    "    # Point suivant\n",
    "    xn = xp + (gradient_step*D)\n",
    "    \n",
    "    # Evolution du gradient, du pas, et du critere\n",
    "    gradient_norm_list.append(norm(gradient_p))\n",
    "    gradient_step_list.append(gradient_step)\n",
    "    critere_list.append(critere)\n",
    "\n",
    "    ##### Boucle sur les iterations\n",
    "\n",
    "    for k in range(iter_max):\n",
    "\n",
    "        # Valeur du critere et du gradient\n",
    "        critere, gradient_n, _ = Oracle(xn, ind)\n",
    "\n",
    "        # Test de convergence\n",
    "        gradient_norm = norm(gradient_n)\n",
    "        if gradient_norm <= threshold:\n",
    "            break\n",
    "            \n",
    "        # Valeur de l'approximation de l'inverse de la Hessienne\n",
    "        delta_x = (xn - xp)\n",
    "        delta_g = gradient_n - gradient_p\n",
    "        denom = np.dot(delta_x, delta_g)\n",
    "        num1 = np.matmul(delta_x.reshape(x0.size,1), np.transpose(delta_g.reshape(x0.size,1)))\n",
    "        num2 = np.matmul(delta_g.reshape(x0.size,1), np.transpose(delta_x.reshape(x0.size,1)))\n",
    "        num3 = np.matmul(delta_x.reshape(x0.size,1), np.transpose(delta_x.reshape(x0.size,1)))\n",
    "        Wn = (Id - num1/denom) @ Wp @ (Id - num2/denom) + num3/denom\n",
    "        #Wn = np.matmul(np.matmul(Id - num1/denom, Wp), Id - num2/denom) + num3/denom\n",
    "\n",
    "        # Direction de descente\n",
    "        D = -np.matmul(Wn, gradient_n)\n",
    "\n",
    "        # Pas du gradient par recherche linéaire\n",
    "        gradient_step = 1 # Trouver un meilleur coefficient\n",
    "        gradient_step, _ = Wolfe(gradient_step, xn, D, Oracle)\n",
    "        \n",
    "        # Mise a jour des variables\n",
    "        xp = xn\n",
    "        gradient_p = gradient_n\n",
    "        Wp = Wn\n",
    "        xn = xp + (gradient_step*D)\n",
    "        \n",
    "        # Evolution du gradient, du pas, et du critere\n",
    "        gradient_norm_list.append(gradient_norm)\n",
    "        gradient_step_list.append(gradient_step)\n",
    "        critere_list.append(critere)\n",
    "\n",
    "    ##### Resultats de l'optimisation\n",
    "\n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient_n\n",
    "    x_opt = xn\n",
    "    time_cpu = process_time() - time_start\n",
    "\n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "\n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "\n",
    "    return critere_opt, gradient_opt, x_opt\n",
    "\n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "\n",
    "    return critere_opt, gradient_opt, x_opt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Monitor_Skel.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#                                                                           #\n",
    "#  MONITEUR D'ENCHAINEMENT POUR LE CALCUL DE L'EQUILIBRE D'UN RESEAU D'EAU  #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "# Verification des resultats\n",
    "#from HydrauliqueP import HydrauliqueP\n",
    "#from HydrauliqueD import HydrauliqueD\n",
    "\n",
    "##### Initialisation de l'algorithme\n",
    "\n",
    "# primal\n",
    "x0 = 0.1 * np.random.normal(size=n-md)\n",
    "\n",
    "##### Minimisation proprement dite\n",
    "\n",
    "# Gradient BFGS Inverse\n",
    "print()\n",
    "print(\"ALGORITHME DE GRADIENT BFGS\")\n",
    "copt, gopt, xopt = BFGS(OraclePG, x0)\n",
    "\n",
    "\n",
    "##### Verification des resultats\n",
    "\n",
    "# primal\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt)\n",
    "\n",
    "\n",
    "Verification(qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentaires :** on retrouve la valeur optimale du critère : -3,734. Elle est obtenue au bout de 24 iterations seulement, pour un temps CPU de 0.008s : BFGS a une efficacité comparable à celle obtenue par Newton à pas fixe. Elle est plus efficace que les autres méthodes implémentées jusque là (Polak-Ribière notamment). La encore, on observe bien une décroissance progressive globale de la norme du gradient au cours de itérations. Le pas de gradient lui augmente au cours des itérations jusqu'à se stabilisé à 1. Enfin, la vérification des équations d'équilibre du réseau est cohérente : les écarts sur les débits sont de l'ordre de $10^{-16}$ et ceux sur les pressions de l'ordre de $10^{-7}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Newton à pas variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Newton_V.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Newton_V.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#                                                                           #\n",
    "#         RESOLUTION D'UN PROBLEME D'OPTIMISATION SANS CONTRAINTES          #\n",
    "#                                                                           #\n",
    "#         Methode de Newton a pas variable                                  #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "def Newton(Oracle, x0):\n",
    "\n",
    "    ##### Initialisation des variables\n",
    "\n",
    "    iter_max = 100\n",
    "    gradient_step = 1\n",
    "    threshold = 0.000001\n",
    "\n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "\n",
    "    time_start = process_time()\n",
    "\n",
    "    x = x0\n",
    "\n",
    "    ##### Boucle sur les iterations\n",
    "\n",
    "    for k in range(iter_max):\n",
    "\n",
    "        # Valeur du critere et du gradient\n",
    "        ind = 7\n",
    "        critere, gradient, hessien, _ = Oracle(x, ind)\n",
    "\n",
    "        # Test de convergence\n",
    "        gradient_norm = norm(gradient)\n",
    "        if gradient_norm <= threshold:\n",
    "            break\n",
    "\n",
    "        # Direction de descente - 2 calculs possible : inversion de la hessienne ou système linéaire\n",
    "        #D = - dot(inv(hessien), gradient)\n",
    "        D = np.linalg.solve(hessien, -gradient)\n",
    "\n",
    "        # Pas du gradient par recherche linéaire\n",
    "        gradient_step = 1 # Trouver un meilleur coefficient\n",
    "        gradient_step, _ = WolfePH(gradient_step, x, D, Oracle)\n",
    "        #print('gradient_step = {}'.format(gradient_step))\n",
    "        \n",
    "        # Mise a jour des variables\n",
    "        x = x + (gradient_step*D)\n",
    "\n",
    "        # Evolution du gradient, du pas, et du critere\n",
    "        gradient_norm_list.append(gradient_norm)\n",
    "        gradient_step_list.append(gradient_step)\n",
    "        critere_list.append(critere)\n",
    "\n",
    "    ##### Resultats de l'optimisation\n",
    "\n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient\n",
    "    x_opt = x\n",
    "    time_cpu = process_time() - time_start\n",
    "\n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "\n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "\n",
    "    return critere_opt, gradient_opt, x_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fichier Monitor_Skel.py :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#                                                                           #\n",
    "#  MONITEUR D'ENCHAINEMENT POUR LE CALCUL DE L'EQUILIBRE D'UN RESEAU D'EAU  #\n",
    "#                                                                           #\n",
    "#############################################################################\n",
    "\n",
    "# Verification des resultats\n",
    "#from HydrauliqueP import HydrauliqueP\n",
    "#from HydrauliqueD import HydrauliqueD\n",
    "\n",
    "##### Initialisation de l'algorithme\n",
    "\n",
    "# primal\n",
    "x0 = 0.1 * np.random.normal(size=n-md)\n",
    "\n",
    "##### Minimisation proprement dite\n",
    "\n",
    "# Newton a pas variable\n",
    "print()\n",
    "print(\"ALGORITHME DE NEWTON A PAS VARIABLE\")\n",
    "copt, gopt, xopt = Newton(OraclePH, x0)\n",
    "\n",
    "##### Verification des resultats\n",
    "\n",
    "# primal\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt)\n",
    "\n",
    "\n",
    "Verification(qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentaires :** on retrouve la valeur optimale du critère : -3,734. Elle est obtenue au bout de 6 iterations, pour un temps CPU de 0.003s. Si on observe encore une décroissance progressive globale de la norme du gradient au cours de itérations, le pas de gradient, lui, ne varie pas au cours des itérations. Il est constant, égale à sa valeur initiale 1. On se retrouve donc finalement avec une méthode de Newton à pas fixe, qu'on a déjà implémenté au début du document... La vérification des équations d'équilibre du réseau est cohérente : les écarts sur les débits sont de l'ordre de $10^{-16}$ et ceux sur les pressions de l'ordre de $10^{-12}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
